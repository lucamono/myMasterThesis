\chapter{Experiments}\label{ch:experiments}
Finding the best grasping pose is not an easy task, especially when the parameters to be estimated do not only concern the
position but also the orientation with which the robot will have to grasp the object. Unlike YOLO and other networks that compute a 2D bounding box, i.e., a region of the image that contains the object, our
approach is based on finding a single, specific point within the image that is most suitable for grasping, while not excluding other eligible points suitable for grasping. All these aspects will be taken into
consideration in this chapter, in which the results obtained after training our neural network will be shown.

\subsection{CNN Setup}
The set of parameters used for the network's training are shown in \tabref{tab:network_training_params}.
\begin{table}
	\centering
    \begin{tabular}{| l | l |}
    \hline
    \textbf{Parameter} & \textbf{Value} \\ \hline
	\emph{Optimizer} & Adam \\
	\emph{AMSGrad} & Disabled \\
	\emph{Momentum} & 0.9 \\
	\emph{Decay} & 0.0 \\
	\emph{Learning rate} & 0.0001 \\
	\emph{Batch size} & 16 \\
	\emph{Max batches} & 4000 \\
    \hline
    \end{tabular}
    \caption{\textbf{Training's parameters.} This Table shows the parameters' setup used to train the network.}
    \label{tab:network_training_params}
\end{table}
Our network has been trained on a subset of images of the acquired dataset, taking a relationship of successes of grasping equal to 1/3 and failures of grasping equal to 2/3, for an
overall of 3 thousands images. This subset allows us to balance the number of successes and failures to ensure the network to learn the correct features of the dataset, avoiding the 
bad case in which the prediction regards only the not admissible grasping points within the image, as depicted in figure \ref{fig:bad_case}.
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.6]{figures/5_experiments/bad_case}
    \caption{\textbf{Bad case of prediction's output.} Picture shows the output of a scenario in which the network has been trained in all 4 thousands images of the our dataset. In this case,
    there are no admissible points of grasping predicted by the network.} 
    \label{fig:bad_case}
\end{figure} 

\section{Results}\label{sec:environment_setup}
From the results we will see that, once trained, the network will be able to predict a distribution of grasping points within the image. A clear example is shown in figure 
\ref{fig:distrib}. In fact, for each grid the network will prefer certain points with a specific confidence score between 0 and 1, the higher the score and the more the point will be
the candidate for grasping object (obviously, where the confidence will be low, it is assumed that there are no objects in that region of image pixels). This confidence distribution
implies that, in addition to the maximum confidence candidate point, i.e., the best grasping point according to the network, there will be other points with very high confidence that
can be classified as grasping points. For this reason, the experiments will be evaluated on two different points of view: the first on the basis of all scenarios with maximum 
confidence score; the second analyzing the first 4 highest points of confidence in the overall confidence's distribution.
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.6]{figures/5_experiments/dist}
    \caption{\textbf{Distribution of predicted point of grasping.} Picture shows: in red, all the predicted points with a low confidence score; in blue, the predicted point of grasping with maximum confidence score;
    in green, the point of grasping predicted with the second best confidence score; in yellow and orange, the 2 remaining points with an high confidence scores.} 
    \label{fig:distrib}
\end{figure}

\subsection{Metrics}
The tests were performed on 2 sets of 50 images each:
\begin{itemize}
 \item \textbf{Not agnostic training objects:} These 50 scenarios (folder \emph{4001\_grasp} up to folder \emph{4050\_grasp} inside the path \emph{/dataset\_luca/test\_image}) contain 
 objects present inside the dataset. It is therefore based on the prediction of admissible grasping points for objects that are not agnostic for the network. Obviously
 there is no dependency with the training set because every scenario tested has been acquired independently of the network's training.  
 \item \textbf{Agnostic training objects:} These 50 scenarios (folder \emph{4051\_grasp} up to folder \emph{4100\_grasp} inside the path \emph{/dataset\_luca/test\_image}) contain objects
 not belonging to the dataset (figure \ref{fig:agnostic_objs}). It is therefore based on the prediction of admissible grasping points for objects never seen before on the network, making them agnostic to it. 
 A fortiori in this case, there is no dependency on the training set because each scenario tested has been acquired independently of the network formation.
\end{itemize}
 \begin{figure}[H]
    \centering
    \includegraphics[scale=0.6]{figures/5_experiments/agnostic_objs}
    \caption{\textbf{Agnostic objects tested.} Picture shows the set of agnostic objects used during the experimental test.} 
    \label{fig:agnostic_objs}
\end{figure}
It is clear that, in the case of the first test set of images containing not agnostic objects, it is easier for the network to identify new feasible grasping points. What is most 
interesting of this thesis' work is in fact to see the behavior of the network with unknown objects, as in the case of second test of images that containing agnostic objects. In 
this way it is possible to test the robustness of the network with the aim of paving the way for future work, useful and applicable for example in various industrial sectors.
 
\subsection{The Maximum Confidence Score}
\tabref{tab:max_score_table_results} shows the results obtained taking into consideration, for each image, the point with the maximum confidence value predicted by the network. As expected, network accuracy on the non-agnostic dataset is
higher than accuracy on the agnostic dataset due to experience, the "knowledge" of various objects encountered during the training phase.

\begin{table}[H]
 \centering

   \begin{tabular}{ llllllll }
   &\multicolumn{5}{c}{ \textbf{Maximum Confidence Point} }\\
   \cmidrule(lr){2-6} \cmidrule(lr){7-8}
   \textbf{Object Set} & \emph{Good Point} & \emph{Bad Point} & \emph{Accuracy} \\
   \cmidrule(lr){1-8}   
   \emph{Not Agnostic} & \cellcolor{green!25}42(50) & 8(50) & 0.84\\
   \emph{Agnostic} & \cellcolor{green!25}31(50) & 19(50) & 0.62 \\
%   \vspace{0.025cm} \\
%   \cline{1-8} \\
   \end{tabular} 
   \caption{\textbf{The maximum confidence score results}}
   \label{tab:max_score_table_results}
\end{table}

\subsection{The high distribution of Confidence Score}
As mentioned above, for each image the network is able to predict a distribution of grasping points, obviously, each of them predicted with a different confidence value. In Tables \ref{tab:blue_table_results}, 
\ref{tab:green_table_results}, \ref{tab:yellow_table_results}, \ref{tab:orange_table_results}  are shown the results obtained taking into account the first 4 confidence points higher in the entire distribution, 
in which each of them is marked with a color related to the higher confidence score in the following order of importance: blue, green, yellow and orange.   

\begin{table}[H]
 \centering
   \begin{tabular}{ llllllll }
   &\multicolumn{5}{c}{ \textbf{Blue Confidence Point} }\\
   \cmidrule(lr){2-6} \cmidrule(lr){7-8}
   \textbf{Object Set} & \emph{Good Point} & \emph{Bad Point} & \emph{Accuracy} \\
   \cmidrule(lr){1-8}   
   \emph{Not Agnostic} & \cellcolor{green!25}42(50) & 8(50) & 0.84 \\
   \emph{Agnostic} & \cellcolor{green!25}31(50) & 19(50) & 0.62 \\
%   \vspace{0.025cm} \\
%   \cline{1-8} \\
   \end{tabular} 
   \caption{\textbf{The first highest confidence score results}.}
   \label{tab:blue_table_results}
\end{table}

\begin{table}[H]
 \centering
   \begin{tabular}{ llllllll }
   &\multicolumn{5}{c}{ \textbf{Green Confidence Point} }\\
   \cmidrule(lr){2-6} \cmidrule(lr){7-8}
   \textbf{Object Set} & \emph{Good Point} & \emph{Bad Point} & \emph{Accuracy} \\
   \cmidrule(lr){1-8}   
   \emph{Not Agnostic} & \cellcolor{green!25}22(50) & 28(50) & 0.44 \\
   \emph{Agnostic} & \cellcolor{green!25}23(50) & 27(50) & 0.46 \\
%   \vspace{0.025cm} \\
%   \cline{1-8} \\
   \end{tabular} 
   \caption{\textbf{The second highest confidence score results}}
   \label{tab:green_table_results}
\end{table}

\begin{table}[H]
 \centering
   \begin{tabular}{ llllllll }
   &\multicolumn{5}{c}{ \textbf{Yellow Confidence Point} }\\
   \cmidrule(lr){2-6} \cmidrule(lr){7-8}
   \textbf{Object Set} & \emph{Good Point} & \emph{Bad Point} & \emph{Accuracy} \\
   \cmidrule(lr){1-8}   
   \emph{Not Agnostic} & \cellcolor{green!25}21(50) & 29(50) & 0.42 \\
   \emph{Agnostic} & \cellcolor{green!25}22(50) & 28(50) & 0.44 \\
%   \vspace{0.025cm} \\
%   \cline{1-8} \\
   \end{tabular} 
   \caption{\textbf{The third highest confidence score results}}
   \label{tab:yellow_table_results}
\end{table}

\begin{table}[H]
 \centering
   \begin{tabular}{ llllllll }
   &\multicolumn{5}{c}{ \textbf{Orange Confidence Point} }\\
   \cmidrule(lr){2-6} \cmidrule(lr){7-8}
   \textbf{Object Set} & \emph{Good Point} & \emph{Bad Point} & \emph{Accuracy} \\
   \cmidrule(lr){1-8}   
   \emph{Not Agnostic} & \cellcolor{green!25}19(50) & 31(50) & 0.38 \\
   \emph{Agnostic} & \cellcolor{green!25}17(50) & 33(50) & 0.34 \\
%   \vspace{0.025cm} \\
%   \cline{1-8} \\
   \end{tabular} 
   \caption{\textbf{The fourth highest confidence score results}}
   \label{tab:orange_table_results}
\end{table}
As expected, the results show how the accuracy of the network decreases gradually through the order of importance of the 4 points considered. However, thanks to the analysis of the results obtained from this 
distribution, we have noticed an interesting aspect regarding the ``Bad Points'' shown in \tabref{tab:blue_table_results}, i.e., all that maximum confidence score points that the network has not been able to predict 
in the correct way. In particular, a test scenario considered as failed due to these points can be considered as a successful scenario considering all those ``Good points'' within the distribution of the 
first 4 points. Two examples are shown in Figures \ref{fig:example1} and \ref{fig:example2}.  

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.6]{figures/5_experiments/example_1}
    \caption{\textbf{Bad point example 1.} Picture shows a scenario where the network fails the grasping prediction for the point with the highest confidence score (in blue). However, the network correctly predicts both 
    second and third points with the highest confidence score (in green and in orange).} 
    \label{fig:example1}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.6]{figures/5_experiments/example_2}
    \caption{\textbf{Bad point example 2.} Picture shows a scenario where the network fails the grasping prediction for the point with the highest confidence score (blue point). However, the network correctly
    predicts the second point with the highest confidence score (green point).} 
    \label{fig:example2}
\end{figure}
Therefore, in a test scenario we can say that among the 4 distribution points candidates for grasping it is not always certain that the point with the highest score of confidence is the best candidate to grasp an
object.

\subsection{Discussion}
to do...

\end{itemize}


