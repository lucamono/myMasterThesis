\chapter{Experiments}\label{ch:experiments}
Finding the best grasping pose is not an easy task, especially when the parameters to be estimated do not only concern the
position but also the orientation with which the robot will have to grasp the object. Unlike YOLO and other networks that compute a 2D bounding box, i.e., a region of the image that contains the object, our
approach is based on finding a single, specific point within the image that is most suitable for grasping, while not excluding other eligible points suitable for grasping. All these aspects will be taken into
consideration in this chapter, in which the results obtained after training our neural network will be shown.

\subsection{Experiments Results}
The set of parameters used for the network's training are shown in \tabref{tab:network_training_params}.
\begin{table}
	\centering
    \begin{tabular}{| l | l |}
    \hline
    \textbf{Parameter} & \textbf{Value} \\ \hline
	\emph{Optimizer} & Adam \\
	\emph{AMSGrad} & Disabled \\
	\emph{Momentum} & 0.9 \\
	\emph{Decay} & 0.0 \\
	\emph{Learning rate} & 0.0001 \\
	\emph{Batch size} & 16 \\
	\emph{Max batches} & 4000 \\
    \hline
    \end{tabular}
    \caption{\textbf{Training's parameters.} This Table shows the parameters' setup used to train the network.}
    \label{tab:network_training_params}
\end{table}
Our network has been trained on a subset of images of the acquired dataset, taking a relationship of successes of grasping equal to 1/3 and failures of grasping equal to 2/3, for an
overall of 3 thousands images. This subset allows us to balance the number of successes and failures to ensure the network to learn the correct features of the dataset, avoiding the 
bad case in which the prediction regards only the not admissible grasping points within the image, as depicted in figure \ref{fig:bad_case}.
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.6]{figures/5_experiments/bad_case}
    \caption{\textbf{Bad case of prediction's output.} Picture shows the output of a scenario in which the network has been trained in all 4 thousands images of the our dataset. In this case,
    there are no admissible points of grasping predicted by the network.} 
    \label{fig:bad_case}
\end{figure} 

\section{Results}\label{sec:environment_setup}
From the results we will see that, once trained, the network will be able to predict a set of grasping points within the image. A clear example is shown in figure 
\ref{fig:distrib}. In fact, for each cell the network will extract a specific point with a predicted confidence score between 0 and 1, the higher the score and the more the point will be the candidate
for grasping an object (obviously, where the confidence will be low, it is assumed that there are no objects in that region of image pixels). Hence, in addition to the maximum confidence candidate point, i.e.,
the best grasping point according to the network, there will be other points with very high confidence that can be classified as grasping points. For this reason, the experiments will be evaluated on 
two different points of view: the first on the basis of all scenarios with maximum confidence score; the second analyzing the first 4 highest points of confidence in the overall grid cells.
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.6]{figures/5_experiments/dist}
    \caption{\textbf{Distribution of predicted point of grasping.} Picture shows: in red, all the predicted points with a low confidence score; in blue, the predicted point of grasping with maximum confidence score;
    in green, the point of grasping predicted with the second best confidence score; in yellow and orange, the 2 remaining points with an high confidence scores.} 
    \label{fig:distrib}
\end{figure}

\subsection{Metrics}
The tests were performed on 2 sets of 100 images each. The tests were carried out on 2 sets of 100 images each. Every single test is considered a successful scenario if and only, given the point of grasping $x,y,\rho,\phi,C$
predicted by the network, the robot manages to grasp an object and lift it up to a height of 30 cm with respect to the board. These sets are composed by:
\begin{itemize}
 \item \textbf{Not agnostic training objects:} These 100 scenarios contain objects present inside the dataset. It is therefore based on the prediction of admissible grasping points for objects that are not agnostic
 for the network. Obviously there is no dependency with the training set because every scenario tested has been acquired independently of the network's training.  
 \item \textbf{Agnostic training objects:} These 100 scenarios contain objects not belonging to the dataset (figure \ref{fig:agnostic_objs}). It is therefore based on the prediction of admissible grasping points 
 for objects never seen before on the network, making them agnostic to it. A fortiori in this case, there is no dependency on the training set because each scenario tested has been acquired independently of the
 network formation.
\end{itemize}
 \begin{figure}[H]
    \centering
    \includegraphics[scale=0.6]{figures/5_experiments/agnostic_objs}
    \caption{\textbf{Agnostic objects tested.} Picture shows the set of agnostic objects used during the experimental test.} 
    \label{fig:agnostic_objs}
\end{figure}
It is clear that, in the case of the first test set of images containing not agnostic objects, it is easier for the network to identify new feasible grasping points. What is most 
interesting of this thesis' work is in fact to see the behavior of the network with unknown objects, as in the case of second test of images that containing agnostic objects. In 
this way it is possible to test the robustness of the network with the aim of paving the way for future work, useful and applicable for example in various industrial sectors.
 
\subsection{The Maximum Confidence Score}
\tabref{tab:max_score_table_results} shows the results obtained taking into consideration, for each image, the point with the maximum confidence value predicted by the network. As expected, network accuracy on the non-agnostic dataset is
higher than accuracy on the agnostic dataset due to experience, the "knowledge" of various objects encountered during the training phase.

\begin{table}[H]
 \centering

   \begin{tabular}{ llllllll }
   &\multicolumn{5}{c}{ \textbf{Maximum Confidence Point} }\\
   \cmidrule(lr){2-6} \cmidrule(lr){7-8}
   \textbf{Object Set} & \emph{Good(All)} & \emph{Bad(All)} & \emph{Accuracy} \\
   \cmidrule(lr){1-8}   
   \emph{Not Agnostic} & 84(100) & 16(100) & 0.84\\
   \emph{Agnostic} & 62(100) & 38(100) & 0.62 \\
%   \vspace{0.025cm} \\
%   \cline{1-8} \\
   \end{tabular} 
   \caption{\textbf{The maximum confidence score results}}
   \label{tab:max_score_table_results}
\end{table}

\subsection{The 4 Highest Confidence Scores}
As mentioned above, for each image the network is able to predict for each cell a grasping point, obviously, each of them predicted with a different confidence value. In Table \ref{tab:4_highest_points_tab} are
shown the results obtained taking into account the first 4 confidence points higher in the entire grid cell distribution, in which each of them is marked with a color related to the higher confidence score in the
following order of importance: blue, green, yellow and orange.   

\begin{table*}[ht!]
	\scriptsize
	\centering
	 \begin{tabular}{ ccccccc }
	 \multicolumn{1}{c}{} & \multicolumn{3}{c}{ \textbf{Not Agnostic}}& \multicolumn{3}{c}{ \textbf{Agnostic}}\\
	 \cmidrule(lr){2-4} \cmidrule(lr){5-7}
	 {\parbox[c]{3cm}{\centering Predicted Point}} & {\parbox[c]{1cm}{\centering Good(All)}} &{\parbox[c]{1cm}{\centering Bad(All)}} &{\parbox[c]{1cm}{\centering Accuracy}} & {\parbox[c]{1cm}{\centering Good(All)}} &{\parbox[c]{1cm}{\centering Bad(All)}} &{\parbox[c]{1cm}{\centering Accuracy}}\\\cline{1-7}\noalign{\vskip 1mm}

	 Blue & 84(100) & 16(100) & 0.84 & 62(100) & 38(100) & 0.62 \\
	 Green & 44(100) & 56(100) & 0.44 & 46(100) & 54(100) & 0.46 \\
	 Yellow & 42(100) & 56(100) & 0.42 & 44(100) & 56(100) & 0.44  \\
	 Orange & 38(100) & 62(100) & 0.38 & 34(100) & 66(100) & 0.34 \\\hline
	 \end{tabular}	
	 \caption{The 4 highest confidence score points predicted by the network. The accuracy of the network has been tested by 2 sets of 100 test images each. The first set contains only not agnostic objects w.r.t. the 
	 network; the second set contains only agnostic objects w.r.t. the network.}
	 \label{tab:4_highest_points_tab}
\end{table*}

As expected, the results show how the accuracy of the network decreases gradually through the order of importance of the 4 points considered. However, thanks to the analysis of the results obtained from this 
distribution, we have noticed an interesting aspect regarding the ``Bad Points'' shown in \tabref{tab:blue_table_results}, i.e., all that maximum confidence score points that the network has not been able to predict 
in the correct way. In particular, a test scenario considered as failed due to these points can be considered as a successful scenario considering all those ``Good points'' within the distribution of the 
first 4 points. Two examples are shown in Figures \ref{fig:example1} and \ref{fig:example2}.  

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.6]{figures/5_experiments/example_1}
    \caption{\textbf{Bad point example 1.} Picture shows a scenario where the network fails the grasping prediction for the point with the highest confidence score (in blue). However, the network correctly predicts both 
    second and third points with the highest confidence score (in green and in orange).} 
    \label{fig:example1}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.6]{figures/5_experiments/example_2}
    \caption{\textbf{Bad point example 2.} Picture shows a scenario where the network fails the grasping prediction for the point with the highest confidence score (blue point). However, the network correctly
    predicts the second point with the highest confidence score (green point).} 
    \label{fig:example2}
\end{figure}
Therefore, in a test scenario we can say that among the 4 distribution points candidates for grasping it is not always certain that the point with the highest score of confidence is the best candidate to grasp an
object.

\newpage
\subsection{Discussion}
From the results obtained from the experiments we showed how the approach of exploiting the features of the images to predict a grasping point produced good and interesting results. We can deduce with certainty that, in 
the majority of the scenarios, the network has learned to predict points suitable for the grasping of objects. Obviously, the best results come from objects that are not agnostic to the network.

Due to the limitation of time and with the cardinality of the dataset(only 4000 acquisitions done), the behaviour who experienced was in line with our expectation. Moreover, the results showed us an interesting
aspect related to the predicted points provided by the network, showing that in some cases of failure scenarios due to the wrong prediction of the point with the highest confidence score turned out to be
successful scenarios for some points below the maximum score.

What interests us most at this point is to understand how far this approach can be improved. Moreover, if it is proved to be a valid solution, it is necessary to understand how to exploit its powerfull in the 
various contexts of robotics, starting from research to possible practical implementations as in the case of industries.

It is clear that this work certainly deserves to be further developed. For example an extension of the dataset through other acquisitions with the robot and also the use of data augmentation would allow us to
draw further and interesting conclusions on the validity of the method. In addition, the behaviour of the network should be tested with a wider range of agnostic objects on the network, in hostile contexts and 
therefore complicated to the vision and detection of objects as in the case of industrial setting in which many objects are piled up in a container with little light available.
\end{itemize}


